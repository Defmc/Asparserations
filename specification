namespace asparserations

  //Namespace for grammar API
  namespace grammar
    class Grammar
      DATA
      class TokenImp : Token
      class NonterminalImp : Nonterminal
      std::map<std::string,TokenImp> _tokens
      std::map<std::string,NonterminalImp> _nonterminals

      METHODS
      Nonterminal& add_nonterminal(const std::string&)
      Token& add_token(const std::string&)
      [const] Token& token_at(const std::string&) [const]
      [const] Nonterminal& nonterminal_at(const std::string&) [const]

    class Symbol
      std::set<Token*>& first_set() = 0      
 
    class Token : public Symbol

    class Nonterminal : public Symbol
      DATA
      std::set<Token> first_set
      std::vector<Production> productions

      METHODS
      getter for first set
      getter for productions

    class Production
      std::vector<const Symbol*> symbols


  //Namespace for generating the state machine
  namespace table

    class Item
      DATA
      const Production& production
      int marker
      const Symbol& lookahead

      METHODS

    class Item_Set
      DATA
      std::set<Item> items

      METHODS
      bool merge(const tem_Set&)

    class State
      std::map<Symbol*, State*>

    class Table
      const std::set<State>& states() const = 0

    class LR_Table : public Table
      const std::set<State>& states() const

    class LALR_Table : public Table
      const std::set<State>& states() const

  namespace codegen
    class Code_Generator
      const std::string& code() const=0;

//Brainstorm

namespace {
  class Parser
  {
    std::vector<State> _state_stack;

    void state0()
    {
      State& state = _state_stack.back();
      if(state.action == shift) {
        Lexer lexer = state.lexer;
        switch(state.symbol) {
        case id:
          auto result = lexer.recognize_id();
	  if(result.second) {
	    state.symbol = result.first;
	    _state_stack.emplace_back(&this->state3);
	    break;
	  }(...)
        case lparens:
          auto result = lexer.recognize_lparens();
       	  if(result.second) {
	    state.symbol = result.first;
	    _state_stack.emplace_back(&this->state2);
	    break;
	  }(...)
	(...)
        default:
	  state.action = reduce;
          _state_stack.pop_back();
	} else if(state.action == reduce) {
	  Lexer lexer = state.lexer;
	  switch(state.symbol) {
	  case plus:
	    switch(state.production) {
	    case 4:
	      _state_stack.emplace_back(&this->state);
	      return;
	    (...)
	    default:
	    }
	  (...)
	  default:
	    state.action = go_to;
	  }
	} else {
	  switch(state.symbol) {
	  case E:
	    switch(state.production) {
	    case 4:
	      _state_stack.push_back(reduce(4));
	    (...)
	    default:
	      break;
	    }
	  (...)
	  default:
	    _state_stack.pop_back();
	  }
	}
      }
    }
  };
  struct State
  {
    const void (Parser::*)(State) function_ptr;
    Symbol symbol;
    Production production;
    Lexer lexer;
  };
}

Node* parse(Lexer& lexer)
{
}


//OR

//Highly compressed struct format

class Parser
{
  //The Token type is actually a function pointer to the
  //lexer's recognizer function
  //Example:
  //Token lparens = Lexer::next_lparens;
  using Token = Lexeme(Lexer::*)();

  std::array<std::pair<,unsigned int>,1> productions {
  };
  using Production = unsigned int;

  //A class template that represents a subsequence of an array
  //C++ doesn't have classes with variable-length array memberss (I don't want
  //to use std::vector because it uses the heap and the generated code should
  //be small and fast) so I pack all of the object's arrays into one large
  //array and keep pointers and sizes into them
  template<class T>
  struct ArrayView
  {
    const T* pointer;
    const unsigned int size;
    ArrayView(T* const, unsigned int)
    T& operator[](unsigned int);
    const T& operator[](unsigned int) const;
  };

  //The following three arrays are the aforementioned large arrays that
  //ArrayView keeps a place in

  //Array of token/state pairs representing shifts
  std::array<std::pair<Token,unsigned int>> shifts {
    {id, 3}, {lparens, 2}
  };

  //Array of productions to reduce to
  std::array<Production> reduce_productions = {
    4
  };

  //ArrayView peeks into above array
  std::array<std::pair<Token,ArrayView<Production>>,1> reduces = {
    {plus, Array(productions.data, 1)}
  };

  //Array of nonterminal/state pairs representing gotos
  std::array<std::pair<Symbol,unsigned int>,1> gotos {
    {E, 4}
  };

  struct State
  {
    ArrayView<std::pair<Token,unsigned int>> shifts;
    ArrayView<std::pair<Token,ArrayView<Production>>> reduces;
    ArrayView<std::pair<Symbol,unsigned int>> gotos;
  };

  //The state of the state ("memento")
  struct StateState or Context
  {
    enum class Action : char {shift, reduce, goto};
    unsigned int index;
    unsigned int production_index;
    Action action;
    Node* node;
  };
};

//OR

//Use free store allocation - lower quality, but no weird addressing system

namespace {

struct Production
{
  //Pointer to function that returns a pointer to the appropriate node,
  //representing the nonterminal to reduce to in the parse tree
  Node*(*node)();
  unsigned int symbol_count;
};

struct State
{
  std::vector<std::pair<Token,unsigned int>>shifts;
  std::vector<std::pair<Token,std::vector<Production*>>> reduces;
  std::map<Symbol,unsigned int> gotos;
};

struct Continuation
{
  enum class Action {shift, reduce, go_to};
  union {
    std::vector<std::pair<Token,unsigned int>>::iterator shift_index;
    std::vector<std::pair<Token,std::vector<Production*>>>::iterator
      reduce_index;
    Symbol symbol;
  };
  Lexer lexer;
  unsigned int state;
  Node* node;
};

}

class Parser
{
  void _enter_state(Continuation&);
  void _reduce();
  std::vector<State> _states;
  std::vector<Continuation> _continuation_stack;
public:
  Parser();
};

void Parser::_enter_state(Continuation& c)
{
  State& s = this->_states.at(c.state);
  Lexer l = c.lexer;
  if(c.action == Continuation::Action::shift) {
    for(auto i = c.shift_index; i != s.shifts.end(); ++i) {
      //Call the token recognization function
      auto result = lexer.*(i->first);
      if(result.second) {
        c.shift_index = i;
	delete c.node;
        c.node = result.first;
        this->_continuation_stack.emplace_back(shift, i->second);
        return;
      }
    }
    c.action = Continuation::Action::reduce;
    c.reduce_index = s.reduces.begin();
  }
  if (c.action == Continuation::Action::reduce) {
    for(auto i = c.reduce_index; i != s.reduces.end(); ++i) {
      auto result = lexer.*(i->first);
      if(result.second) {
        c.reduce_index = i;
	this->_reduce();
	return;
      }
    }
    c.action = Continuation::Action::go_to;
  }
  if(c.action == Continuation::Action::go_to) {
    auto result = s.gotos.find(c.symbol);
    if(result.second) {
      this->_continuation_stack.emplace_back(Continuation::Action::Shift,
                                             result.first->shift);
      return;
    }
  }
  this->_continuation_stack.pop_back();
}

void Parser::_reduce()
{

}

Parser::Parser()
{
  _continuation_stack.emplace_back(Continuation::Action::shift, 0);
  while(!this->_continuation_stack.empty()) {
    this->_enter_state(this->_continuation_stack.back());
  }
}

//JSON Output
{
  "grammar" : {
    "tokens" : [
      "e"
    ],
    "nonterminals" : [
      "S" : {
        "root" : [
	  {
	    "id" : "e",
	    "isToken" : true
	  }
	]
      }
    ]
  },
  "table" : [
    {
      "shifts" : {
        "e" : 1
      },
      "reductions" : {
        "e" : [
	   {
	     "nonterminal" : "S",
	     "production" : "root"
	   }
	]
      },
      "gotos" : {
        "S" : 1
      }
    }
  ]
}
